import base64
import hashlib
import os
import tempfile
from dataclasses import dataclass
from pathlib import Path
from typing import Any, List, Dict, Optional


# è¯´æ˜ï¼š
# - æœ¬æ–‡ä»¶æä¾›"å›¾ç‰‡ç›¸ä¼¼æ£€ç´¢"çš„èƒ½åŠ›ï¼šæŠŠæ•°æ®åº“å›¾ç‰‡å‘é‡åŒ–å­˜å…¥ ChromaDBï¼Œç„¶åå¯¹ç”¨æˆ·ä¸Šä¼ å›¾ç‰‡åšç›¸ä¼¼åº¦æŸ¥è¯¢
# - è®¾è®¡ä¸Šä¸å¤„ç† HTTPï¼›ä¸Šå±‚ä¼šä¼ å…¥ base64 æˆ–æœ¬åœ°æ–‡ä»¶è·¯å¾„
@dataclass(frozen=True)
class VisionMatch:
    path: str
    score: float


def _try_import_backend():
    # å¯é€‰ä¾èµ–ï¼šå¦‚æœç¯å¢ƒæ²¡è£… chromadb / open_clipï¼Œåˆ™è¿”å› None
    try:
        import chromadb  # type: ignore
        from langchain_experimental.open_clip import OpenCLIPEmbeddings  # type: ignore
        return chromadb, OpenCLIPEmbeddings
    except ImportError as e:
        # é™é»˜å¤„ç†å¯¼å…¥é”™è¯¯ï¼Œåªåœ¨ DEBUG æ¨¡å¼ä¸‹è¾“å‡ºè¯¦ç»†ä¿¡æ¯
        import logging
        logger = logging.getLogger(__name__)
        logger.debug(f"[vision_client] å›¾ç‰‡è¯†åˆ«ä¾èµ–æœªå®‰è£…: {e}")
        logger.info("[vision_client] ğŸ’¡ æç¤º: å¦‚éœ€ä½¿ç”¨å›¾ç‰‡è¯†åˆ«åŠŸèƒ½ï¼Œè¯·å®‰è£…ä¾èµ–: pip install chromadb langchain-experimental open-clip-torch torch torchvision")
        return None, None
    except Exception as e:
        import logging
        import traceback
        logger = logging.getLogger(__name__)
        logger.warning(f"[vision_client] å¯¼å…¥ä¾èµ–æ—¶å‡ºé”™: {e}")
        if logger.isEnabledFor(logging.DEBUG):
            traceback.print_exc()
        return None, None


def _list_images(dataset_folder: str) -> List[str]:
    # éå†å›¾åƒåº“ç›®å½•ï¼Œæ”¶é›†æ”¯æŒçš„å›¾ç‰‡æ–‡ä»¶
    image_paths: List[str] = []
    valid_extensions = (".jpg", ".jpeg", ".png", ".webp", ".bmp")
    for root, _, files in os.walk(dataset_folder):
        for file in files:
            if file.lower().endswith(valid_extensions):
                image_paths.append(os.path.join(root, file))
    return image_paths


def _extract_label(image_path: str, dataset_folder: str) -> str:
    """ä»å›¾ç‰‡è·¯å¾„ä¸­æå–æ ‡ç­¾ï¼ˆçˆ¶æ–‡ä»¶å¤¹åç§°ï¼‰"""
    rel_path = os.path.relpath(image_path, dataset_folder)
    parts = rel_path.split(os.sep)
    if len(parts) >= 2:
        return parts[-2]  # ç›´æ¥çˆ¶æ–‡ä»¶å¤¹ä½œä¸ºæ ‡ç­¾
    return "unknown"


_MODEL = None
_COLLECTION = None
_INDEXED_DATASET = None


def _project_root() -> Path:
    # ç»Ÿä¸€ä»¥é¡¹ç›®æ ¹ä½œä¸ºåŸºå‡†ï¼Œä¿è¯ä»ä»»æ„ cwd å¯åŠ¨éƒ½èƒ½æ‰¾åˆ° image_data/
    # vision_client.py ä½äº: backend/app/services/vision_client.py
    # é¡¹ç›®æ ¹ç›®å½•åº”è¯¥æ˜¯: backend/app/services/ -> backend/app/ -> backend/ -> é¡¹ç›®æ ¹
    current_file = Path(__file__).resolve()
    # ä» backend/app/services/vision_client.py åˆ°é¡¹ç›®æ ¹éœ€è¦ä¸Š3çº§
    project_root = current_file.parents[3]
    
    # éªŒè¯ï¼šæ£€æŸ¥ image_data ç›®å½•æ˜¯å¦å­˜åœ¨
    image_data_path = project_root / "image_data"
    if not image_data_path.exists():
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•ä» backend ç›®å½•å‘ä¸Šæ‰¾
        backend_dir = current_file.parents[2]  # backend/
        project_root_alt = backend_dir.parent  # é¡¹ç›®æ ¹
        if (project_root_alt / "image_data").exists():
            return project_root_alt
    
    return project_root


def _resolve_dataset_folder(dataset_folder: str) -> str:
    # æ”¯æŒä¼ å…¥ç»å¯¹è·¯å¾„ï¼›å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„åˆ™ç›¸å¯¹é¡¹ç›®æ ¹è§£æ
    import logging
    logger = logging.getLogger(__name__)
    
    try:
        p = Path(dataset_folder).expanduser()
        if p.is_absolute():
            resolved_path = str(p.resolve())
            logger.debug(f"[vision_client] ä½¿ç”¨ç»å¯¹è·¯å¾„: {resolved_path}")
            if not os.path.exists(resolved_path):
                logger.warning(f"[vision_client] è·¯å¾„ä¸å­˜åœ¨: {resolved_path}")
            return resolved_path
        
        project_root = _project_root()
        resolved_path = str((project_root / p).resolve())
        logger.debug(f"[vision_client] è§£æè·¯å¾„: {dataset_folder} -> {resolved_path}")
        logger.debug(f"[vision_client] é¡¹ç›®æ ¹ç›®å½•: {project_root}")
        
        if not os.path.exists(resolved_path):
            logger.warning(f"[vision_client] è·¯å¾„ä¸å­˜åœ¨: {resolved_path}")
            logger.warning(f"[vision_client] è¯·æ£€æŸ¥ image_data ç›®å½•æ˜¯å¦åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹")
        
        return resolved_path
    except Exception as e:
        import logging
        logger = logging.getLogger(__name__)
        logger.error(f"[vision_client] è·¯å¾„è§£æå¤±è´¥: {e}", exc_info=True)
        # ERROR_CODE: VISION_ERR_PATH_RESOLVE_FAILED
        raise RuntimeError(f"VISION_ERR_PATH_RESOLVE_FAILED: {str(e)}")


def _chroma_persist_dir() -> str:
    p = (_project_root() / "chroma").resolve()
    os.makedirs(p, exist_ok=True)
    return str(p)


def _collection_name_for_dataset(dataset_folder: str) -> str:
    h = hashlib.sha1(dataset_folder.encode("utf-8")).hexdigest()
    return f"visual_search_{h}"


def _image_id(image_path: str) -> str:
    return hashlib.sha1(image_path.encode("utf-8")).hexdigest()


def _normalize_embeddings(vectors: Any) -> List[List[float]]:
    if (
        isinstance(vectors, list)
        and len(vectors) > 0
        and isinstance(vectors[0], list)
        and len(vectors[0]) > 0
        and isinstance(vectors[0][0], list)
    ):
        return [v[0] for v in vectors]
    return vectors


def _scan_dataset(dataset_folder: str) -> List[Dict[str, Any]]:
    items: List[Dict[str, Any]] = []
    for p in _list_images(dataset_folder):
        try:
            mtime = float(os.path.getmtime(p))
        except Exception:
            mtime = 0.0
        items.append(
            {
                "id": _image_id(p),
                "path": p,
                "mtime": mtime,
                "label": _extract_label(p, dataset_folder),
            }
        )
    items.sort(key=lambda x: x["path"])
    return items


def _sync_collection(dataset_folder: str, collection):
    assert _MODEL is not None

    current_items = _scan_dataset(dataset_folder)
    if not current_items:
        # ERROR_CODE: VISION_ERR_DATASET_EMPTY
        raise RuntimeError(f"VISION_ERR_DATASET_EMPTY: No valid images in {dataset_folder}")

    current_by_id = {x["id"]: x for x in current_items}

    existing_by_id: Dict[str, Dict[str, Any]] = {}
    try:
        limit = None
        if hasattr(collection, "count"):
            try:
                limit = int(collection.count())
            except Exception:
                limit = None
        if limit:
            got = collection.get(limit=limit, include=["metadatas", "documents"])
        else:
            got = collection.get(include=["metadatas", "documents"])
        ids = got.get("ids") or []
        docs = got.get("documents") or []
        metas = got.get("metadatas") or []
        for i, _id in enumerate(ids):
            meta = metas[i] if i < len(metas) else None
            doc = docs[i] if i < len(docs) else None
            if not _id:
                continue
            existing_by_id[str(_id)] = {"document": doc, "metadata": meta or {}}
    except Exception:
        existing_by_id = {}

    existing_ids = set(existing_by_id.keys())
    current_ids = set(current_by_id.keys())

    ids_to_delete = sorted(existing_ids - current_ids)
    ids_to_add: List[str] = []
    ids_to_update: List[str] = []

    for _id, item in current_by_id.items():
        if _id not in existing_by_id:
            ids_to_add.append(_id)
            continue
        meta = existing_by_id[_id].get("metadata") or {}
        doc = existing_by_id[_id].get("document")
        prev_path = meta.get("path") or doc
        prev_mtime = meta.get("mtime")
        if prev_path != item["path"] or prev_mtime != item["mtime"]:
            ids_to_update.append(_id)

    if ids_to_delete:
        try:
            collection.delete(ids=ids_to_delete)
        except Exception:
            pass

    def _write_items(item_ids: List[str], *, mode: str):
        if not item_ids:
            return
        batch_size = 64
        for i in range(0, len(item_ids), batch_size):
            chunk_ids = item_ids[i : i + batch_size]
            chunk_items = [current_by_id[_id] for _id in chunk_ids]
            chunk_paths = [x["path"] for x in chunk_items]
            chunk_vectors = _normalize_embeddings(_MODEL.embed_image(uris=chunk_paths))
            chunk_metadatas = [
                {"path": x["path"], "mtime": x["mtime"], "label": x["label"]} for x in chunk_items
            ]
            if mode == "upsert" and hasattr(collection, "upsert"):
                collection.upsert(
                    ids=chunk_ids,
                    documents=chunk_paths,
                    embeddings=chunk_vectors,
                    metadatas=chunk_metadatas,
                )
            else:
                if mode == "upsert":
                    try:
                        collection.delete(ids=chunk_ids)
                    except Exception:
                        pass
                collection.add(
                    ids=chunk_ids,
                    documents=chunk_paths,
                    embeddings=chunk_vectors,
                    metadatas=chunk_metadatas,
                )

    _write_items(ids_to_add, mode="add")
    _write_items(ids_to_update, mode="upsert")


def _guess_mime_from_path(path: str) -> str:
    ext = os.path.splitext(path)[1].lower()
    if ext == ".jpg" or ext == ".jpeg":
        return "image/jpeg"
    if ext == ".png":
        return "image/png"
    if ext == ".webp":
        return "image/webp"
    if ext == ".bmp":
        return "image/bmp"
    return "application/octet-stream"


def _bytes_to_data_url(data: bytes, mime: str) -> str:
    b64 = base64.b64encode(data).decode("ascii")
    return f"data:{mime};base64,{b64}"


def _file_to_data_url(path: str) -> Optional[str]:
    try:
        with open(path, "rb") as f:
            data = f.read()
        return _bytes_to_data_url(data, _guess_mime_from_path(path))
    except Exception:
        return None


def _ensure_index(dataset_folder: str):
    # ç¡®ä¿å·²ä¸º dataset_folder å»ºç«‹æ£€ç´¢ç´¢å¼•ï¼ˆå‘é‡åŒ– + å†™å…¥ Chroma collectionï¼‰
    global _MODEL, _COLLECTION, _INDEXED_DATASET

    chromadb, OpenCLIPEmbeddings = _try_import_backend()
    if not chromadb or not OpenCLIPEmbeddings:
        # ERROR_CODE: VISION_ERR_BACKEND_MISSING
        import logging
        logger = logging.getLogger(__name__)
        logger.error("[vision_client] å›¾ç‰‡è¯†åˆ«ä¾èµ–æœªå®‰è£…")
        logger.error("[vision_client] è¯·è¿è¡Œ: pip install chromadb langchain-experimental open-clip-torch torch torchvision")
        raise RuntimeError("VISION_ERR_BACKEND_MISSING: ç¼ºå°‘å›¾ç‰‡è¯†åˆ«ä¾èµ–åŒ…ã€‚è¯·å®‰è£…: pip install chromadb langchain-experimental open-clip-torch torch torchvision")

    if _INDEXED_DATASET == dataset_folder and _MODEL is not None and _COLLECTION is not None:
        return

    if not os.path.exists(dataset_folder):
        # ERROR_CODE: VISION_ERR_DATASET_NOT_FOUND
        raise RuntimeError(f"VISION_ERR_DATASET_NOT_FOUND: {dataset_folder}")

    try:
        _MODEL = OpenCLIPEmbeddings(model_name="ViT-B-32", checkpoint="laion2b_s34b_b79k")

        client = chromadb.PersistentClient(path=_chroma_persist_dir())
        collection = client.get_or_create_collection(name=_collection_name_for_dataset(dataset_folder))
        _sync_collection(dataset_folder, collection)

        _COLLECTION = collection
        _INDEXED_DATASET = dataset_folder
    except Exception as e:
        # ERROR_CODE: VISION_ERR_INDEXING_FAILED
        raise RuntimeError(f"VISION_ERR_INDEXING_FAILED: {str(e)}")


def recognize_image_path(
    *,
    image_path: str,
    dataset_folder: str = "image_data",
    top_k: int = 3,
) -> Dict[str, Any]:
    # è¾“å…¥ï¼šæœ¬åœ°å›¾ç‰‡è·¯å¾„
    dataset_folder = _resolve_dataset_folder(dataset_folder)
    _ensure_index(dataset_folder)
    
    assert _MODEL is not None
    assert _COLLECTION is not None

    import logging
    logger = logging.getLogger(__name__)
    
    # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¯è¯»
    if not os.path.exists(image_path):
        logger.error(f"[vision_client] å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        raise RuntimeError(f"VISION_ERR_QUERY_IMAGE_NOT_FOUND: {image_path}")
    
    # æ£€æŸ¥æ–‡ä»¶æƒé™
    if not os.access(image_path, os.R_OK):
        logger.error(f"[vision_client] å›¾ç‰‡æ–‡ä»¶æ— è¯»å–æƒé™: {image_path}")
        logger.error(f"[vision_client] æ–‡ä»¶ä¿¡æ¯: exists={os.path.exists(image_path)}, isfile={os.path.isfile(image_path)}")
        raise RuntimeError(f"VISION_ERR_QUERY_IMAGE_PERMISSION_DENIED: {image_path}")
    
    try:
        file_size = os.path.getsize(image_path)
        logger.debug(f"[vision_client] å¼€å§‹å¤„ç†å›¾ç‰‡: {image_path}, å¤§å°: {file_size} bytes")
        
        # æå–å›¾ç‰‡ç‰¹å¾å‘é‡
        logger.debug(f"[vision_client] è°ƒç”¨ embed_image æå–ç‰¹å¾...")
        
        # åœ¨ Windows ä¸Šï¼Œä½¿ç”¨ç»å¯¹è·¯å¾„ç¡®ä¿æ–‡ä»¶å¯è®¿é—®
        abs_image_path = os.path.abspath(image_path)
        logger.debug(f"[vision_client] åŸå§‹è·¯å¾„: {image_path}")
        logger.debug(f"[vision_client] ç»å¯¹è·¯å¾„: {abs_image_path}")
        
        # å†æ¬¡éªŒè¯ç»å¯¹è·¯å¾„çš„æ–‡ä»¶å¯è®¿é—®æ€§
        if not os.path.exists(abs_image_path):
            raise RuntimeError(f"VISION_ERR_QUERY_IMAGE_NOT_FOUND: {abs_image_path}")
        if not os.access(abs_image_path, os.R_OK):
            raise RuntimeError(f"VISION_ERR_QUERY_IMAGE_PERMISSION_DENIED: {abs_image_path}")
        
        # ä½¿ç”¨ç»å¯¹è·¯å¾„è°ƒç”¨ embed_image
        query_vector = _MODEL.embed_image(uris=[abs_image_path])
        query_vector = _normalize_embeddings(query_vector)
        logger.debug(f"[vision_client] ç‰¹å¾å‘é‡æå–å®Œæˆï¼Œç»´åº¦: {len(query_vector[0]) if query_vector and len(query_vector) > 0 else 0}")

        # åœ¨å‘é‡åº“ä¸­æœç´¢
        logger.debug(f"[vision_client] åœ¨å‘é‡åº“ä¸­æœç´¢ç›¸ä¼¼å›¾ç‰‡...")
        results = _COLLECTION.query(query_embeddings=query_vector, n_results=top_k)
        top_matches = results["documents"][0]
        top_scores = results["distances"][0]
        logger.debug(f"[vision_client] æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(top_matches)} ä¸ªå€™é€‰ç»“æœ")

        matches: List[Dict[str, Any]] = []
        for i, p in enumerate(top_matches):
            score = 1 - float(top_scores[i])
            label = _extract_label(p, dataset_folder)
            matches.append({"path": p, "score": score, "label": label})
            logger.debug(f"[vision_client] åŒ¹é… [{i+1}]: {label} (è·¯å¾„: {p}, ç›¸ä¼¼åº¦: {score:.4f})")
        
        logger.info(f"[vision_client] è¯†åˆ«æˆåŠŸï¼Œè¿”å› {len(matches)} ä¸ªåŒ¹é…ç»“æœ")
        return {"matches": matches, "status": "success"}
    except PermissionError as e:
        logger.error(f"[vision_client] æƒé™é”™è¯¯: {e}")
        logger.error(f"[vision_client] æ–‡ä»¶è·¯å¾„: {image_path}")
        logger.error(f"[vision_client] æ–‡ä»¶å­˜åœ¨: {os.path.exists(image_path)}")
        logger.error(f"[vision_client] æ–‡ä»¶å¯è¯»: {os.access(image_path, os.R_OK) if os.path.exists(image_path) else False}")
        raise RuntimeError(f"VISION_ERR_SEARCH_EXECUTION_FAILED: æƒé™è¢«æ‹’ç» - {image_path}ã€‚é”™è¯¯: {str(e)}")
    except Exception as e:
        logger.error(f"[vision_client] å›¾ç‰‡è¯†åˆ«å¤±è´¥: {e}", exc_info=True)
        logger.error(f"[vision_client] æ–‡ä»¶è·¯å¾„: {image_path}")
        logger.error(f"[vision_client] æ–‡ä»¶å­˜åœ¨: {os.path.exists(image_path)}")
        # ERROR_CODE: VISION_ERR_SEARCH_EXECUTION_FAILED
        raise RuntimeError(f"VISION_ERR_SEARCH_EXECUTION_FAILED: {str(e)}")


def recognize_image_base64(
    *,
    image_base64: str,
    dataset_folder: str = "image_data",
    top_k: int = 3,
) -> Dict[str, Any]:
    # è¾“å…¥ï¼šå‰ç«¯ DataURL æˆ–çº¯ base64
    dataset_folder = _resolve_dataset_folder(dataset_folder)
    
    try:
        raw0 = image_base64.strip()
        query_image_data_url = raw0 if raw0.startswith("data:") else f"data:image/jpeg;base64,{raw0}"
        raw = raw0
        if raw.startswith("data:"):
            raw = raw.split(",", 1)[-1]
        data = base64.b64decode(raw, validate=False)
    except Exception as e:
        # ERROR_CODE: VISION_ERR_BASE64_DECODE_FAILED
        raise RuntimeError(f"VISION_ERR_BASE64_DECODE_FAILED: {str(e)}")

    # ä½¿ç”¨ mkstemp åˆ›å»ºä¸´æ—¶æ–‡ä»¶ï¼Œé¿å… Windows æƒé™é—®é¢˜
    temp_fd = None
    temp_path = None
    try:
        import logging
        logger = logging.getLogger(__name__)
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ï¼ˆWindows å…¼å®¹æ–¹å¼ï¼‰
        temp_fd, temp_path = tempfile.mkstemp(suffix=".jpg", prefix="vision_")
        logger.debug(f"[vision_client] åˆ›å»ºä¸´æ—¶æ–‡ä»¶: {temp_path}")
        
        try:
            # ä½¿ç”¨æ–‡ä»¶æè¿°ç¬¦å†™å…¥æ•°æ®
            with os.fdopen(temp_fd, 'wb') as f:
                f.write(data)
                f.flush()
            # æ–‡ä»¶æè¿°ç¬¦ä¼šåœ¨ with è¯­å¥ä¸­è‡ªåŠ¨å…³é—­
            temp_fd = None
            
            # åœ¨ Windows ä¸Šï¼Œç¡®ä¿æ–‡ä»¶æœ‰è¯»å–æƒé™
            # ä½¿ç”¨ stat æ¨¡å—è®¾ç½®æ–‡ä»¶æƒé™ï¼ˆå¦‚æœç³»ç»Ÿæ”¯æŒï¼‰
            try:
                import stat
                # è®¾ç½®æ–‡ä»¶ä¸ºå¯è¯»å¯å†™ï¼ˆç”¨æˆ·ã€ç»„ã€å…¶ä»–ï¼‰
                os.chmod(temp_path, stat.S_IRUSR | stat.S_IWUSR | stat.S_IRGRP | stat.S_IROTH)
                logger.debug(f"[vision_client] å·²è®¾ç½®ä¸´æ—¶æ–‡ä»¶æƒé™: {temp_path}")
            except Exception as chmod_error:
                # åœ¨æŸäº›ç³»ç»Ÿä¸Š chmod å¯èƒ½ä¸å¯ç”¨ï¼Œå¿½ç•¥é”™è¯¯
                logger.debug(f"[vision_client] æ— æ³•è®¾ç½®æ–‡ä»¶æƒé™ï¼ˆå¯å¿½ç•¥ï¼‰: {chmod_error}")
        except Exception as e:
            # å¦‚æœå†™å…¥å¤±è´¥ï¼Œç¡®ä¿å…³é—­æ–‡ä»¶æè¿°ç¬¦
            if temp_fd is not None:
                try:
                    os.close(temp_fd)
                except Exception:
                    pass
            raise
        
        # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¯è¯»
        if not os.path.exists(temp_path):
            raise RuntimeError(f"ä¸´æ—¶æ–‡ä»¶åˆ›å»ºå¤±è´¥: {temp_path}")
        
        file_size = os.path.getsize(temp_path)
        logger.debug(f"[vision_client] ä¸´æ—¶æ–‡ä»¶å·²åˆ›å»ºï¼Œå¤§å°: {file_size} bytes")
        
        # å†æ¬¡éªŒè¯æ–‡ä»¶æƒé™ï¼ˆåœ¨è°ƒç”¨è¯†åˆ«å‰ï¼‰
        if not os.access(temp_path, os.R_OK):
            logger.error(f"[vision_client] ä¸´æ—¶æ–‡ä»¶æ— è¯»å–æƒé™: {temp_path}")
            raise RuntimeError(f"ä¸´æ—¶æ–‡ä»¶æ— è¯»å–æƒé™: {temp_path}")
        
        # å°è¯•æ‰“å¼€æ–‡ä»¶éªŒè¯å¯è®¿é—®æ€§
        try:
            with open(temp_path, 'rb') as test_f:
                test_f.read(1)  # å°è¯•è¯»å–ä¸€ä¸ªå­—èŠ‚
            logger.debug(f"[vision_client] ä¸´æ—¶æ–‡ä»¶æƒé™éªŒè¯é€šè¿‡ï¼Œå‡†å¤‡è°ƒç”¨è¯†åˆ«å‡½æ•°")
        except PermissionError as e:
            logger.error(f"[vision_client] æ— æ³•è¯»å–ä¸´æ—¶æ–‡ä»¶: {e}")
            raise RuntimeError(f"æ— æ³•è¯»å–ä¸´æ—¶æ–‡ä»¶: {temp_path}, é”™è¯¯: {str(e)}")
        
        # è°ƒç”¨è¯†åˆ«å‡½æ•°ï¼ˆç¡®ä¿æ–‡ä»¶åœ¨è¯†åˆ«è¿‡ç¨‹ä¸­ä¿æŒå¯è®¿é—®ï¼‰
        result = recognize_image_path(image_path=temp_path, dataset_folder=dataset_folder, top_k=top_k)
        matches = result.get("matches") or []
        
        # ä¸ºåŒ¹é…ç»“æœæ·»åŠ å›¾ç‰‡æ•°æ® URL
        for m in matches:
            p = m.get("path") if isinstance(m, dict) else None
            if isinstance(p, str) and p:
                m["image_data_url"] = _file_to_data_url(p)
        
        result["query_image_data_url"] = query_image_data_url
        logger.debug(f"[vision_client] è¯†åˆ«å®Œæˆï¼Œæ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…ç»“æœ")
        
        return result
    except Exception as e:
        import logging
        logger = logging.getLogger(__name__)
        logger.error(f"[vision_client] å¤„ç†ä¸´æ—¶æ–‡ä»¶æ—¶å‡ºé”™: {e}", exc_info=True)
        # é€ä¼ ä¸‹æ¸¸é”™è¯¯
        if "VISION_ERR" in str(e):
            raise
        raise RuntimeError(f"VISION_ERR_TEMPFILE_OP_FAILED: {str(e)}")
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_fd is not None:
            try:
                os.close(temp_fd)
            except Exception:
                pass
        if temp_path and os.path.exists(temp_path):
            try:
                os.unlink(temp_path)
                import logging
                logger = logging.getLogger(__name__)
                logger.debug(f"[vision_client] å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {temp_path}")
            except Exception as e:
                import logging
                logger = logging.getLogger(__name__)
                logger.warning(f"[vision_client] åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {temp_path}, é”™è¯¯: {e}")


"""
æ‰¹é‡æ•°æ®å¯¼å…¥è„šæœ¬
æ”¯æŒä»å¤šä¸ª JSON æ–‡ä»¶æˆ–ç›®å½•æ‰¹é‡å¯¼å…¥èŠ‚ç‚¹å’Œè¾¹æ•°æ®åˆ°æ•°æ®åº“
"""
import asyncio
import json
import sys
import os
import glob
from pathlib import Path
from typing import List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from sqlalchemy import select, delete
from app.db import AsyncSessionLocal, init_db
from app.models import Node, Edge, NodeType, EdgeType


async def import_map_data(json_file: str, clear_existing: bool = False, verbose: bool = True):
    """
    ä» JSON æ–‡ä»¶å¯¼å…¥åœ°å›¾æ•°æ®
    
    Args:
        json_file: JSON æ–‡ä»¶è·¯å¾„
        clear_existing: æ˜¯å¦æ¸…é™¤ç°æœ‰æ•°æ®ï¼ˆåªåœ¨ç¬¬ä¸€ä¸ªæ–‡ä»¶æ—¶ç”Ÿæ•ˆï¼‰
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    """
    # è¯»å– JSON æ–‡ä»¶
    if verbose:
        print(f"\nğŸ“– è¯»å–æ–‡ä»¶: {json_file}")
    
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {json_file}")
        return False
    except json.JSONDecodeError as e:
        print(f"âŒ JSON è§£æé”™è¯¯ ({json_file}): {e}")
        return False
    
    nodes_data = data.get('nodes', [])
    edges_data = data.get('edges', [])
    
    if verbose:
        print(f"ğŸ“Š å‘ç° {len(nodes_data)} ä¸ªèŠ‚ç‚¹, {len(edges_data)} æ¡è¾¹")
    
    async with AsyncSessionLocal() as session:
        try:
            # æ¸…é™¤ç°æœ‰æ•°æ®ï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡å¯¼å…¥æ—¶ï¼‰
            if clear_existing:
                if verbose:
                    print("ğŸ—‘ï¸  æ¸…é™¤ç°æœ‰æ•°æ®...")
                await session.execute(delete(Edge))
                await session.execute(delete(Node))
                await session.commit()
                if verbose:
                    print("âœ… ç°æœ‰æ•°æ®å·²æ¸…é™¤")
            
            # å¯¼å…¥èŠ‚ç‚¹
            if verbose:
                print("ğŸ“¥ å¯¼å…¥èŠ‚ç‚¹...")
            imported_nodes = 0
            updated_nodes = 0
            skipped_nodes = 0
            
            for node_data in nodes_data:
                node_id = node_data.get('id')
                
                if not node_id:
                    if verbose:
                        print(f"âš ï¸  è·³è¿‡æ— æ•ˆèŠ‚ç‚¹: {node_data}")
                    skipped_nodes += 1
                    continue
                
                # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å·²å­˜åœ¨
                result = await session.execute(
                    select(Node).where(Node.id == node_id)
                )
                existing_node = result.scalar_one_or_none()
                
                # æ¨æ–­èŠ‚ç‚¹ç±»å‹
                node_type = NodeType.OTHER.value
                name_upper = node_data.get('name', '').upper()
                id_upper = node_id.upper()
                
                if 'STAIR' in id_upper or 'STAIR' in name_upper:
                    node_type = NodeType.STAIRS.value
                elif 'LIFT' in id_upper or 'ELEVATOR' in name_upper:
                    node_type = NodeType.LIFT.value
                elif 'RESTROOM' in name_upper or 'TOILET' in name_upper:
                    node_type = NodeType.RESTROOM.value
                elif 'ENTRANCE' in name_upper or 'GATE' in name_upper:
                    node_type = NodeType.ENTRANCE.value
                elif 'CORRIDOR' in name_upper or 'HALL' in name_upper:
                    node_type = NodeType.CORRIDOR.value
                else:
                    node_type = NodeType.CLASSROOM.value
                
                if existing_node:
                    # æ›´æ–°ç°æœ‰èŠ‚ç‚¹ï¼ˆä¿ç•™åæ ‡ï¼‰
                    existing_node.name = node_data.get('name', node_id)
                    existing_node.detail = node_data.get('detail')
                    existing_node.floor = node_data.get('floor', 1)
                    existing_node.node_type = node_type
                    # å¦‚æœ JSON ä¸­æœ‰åæ ‡ï¼Œæ›´æ–°åæ ‡
                    if 'x' in node_data:
                        existing_node.x = node_data['x']
                    if 'y' in node_data:
                        existing_node.y = node_data['y']
                    updated_nodes += 1
                else:
                    # åˆ›å»ºæ–°èŠ‚ç‚¹
                    node = Node(
                        id=node_id,
                        name=node_data.get('name', node_id),
                        detail=node_data.get('detail'),
                        floor=node_data.get('floor', 1),
                        x=node_data.get('x'),
                        y=node_data.get('y'),
                        node_type=node_type,
                    )
                    session.add(node)
                    imported_nodes += 1
            
            await session.commit()
            if verbose:
                print(f"âœ… èŠ‚ç‚¹å¯¼å…¥å®Œæˆ: æ–°å¢ {imported_nodes}, æ›´æ–° {updated_nodes}, è·³è¿‡ {skipped_nodes}")
            
            # å¯¼å…¥è¾¹
            if verbose:
                print("ğŸ“¥ å¯¼å…¥è¾¹...")
            imported_edges = 0
            updated_edges = 0
            skipped_edges = 0
            
            for edge_data in edges_data:
                from_id = edge_data.get('from')
                to_id = edge_data.get('to')
                
                if not from_id or not to_id:
                    if verbose:
                        print(f"âš ï¸  è·³è¿‡æ— æ•ˆè¾¹: {edge_data}")
                    skipped_edges += 1
                    continue
                
                # æ£€æŸ¥è¾¹æ˜¯å¦å·²å­˜åœ¨
                result = await session.execute(
                    select(Edge).where(
                        Edge.from_node_id == from_id,
                        Edge.to_node_id == to_id
                    )
                )
                existing_edge = result.scalar_one_or_none()
                
                # ç¡®å®šè¾¹ç±»å‹
                edge_type = edge_data.get('type', 'normal')
                if edge_type not in [e.value for e in EdgeType]:
                    edge_type = EdgeType.NORMAL.value
                
                # åˆ¤æ–­æ˜¯å¦ä¸ºå‚ç›´ç§»åŠ¨
                is_vertical = edge_type in [EdgeType.STAIRS.value, EdgeType.LIFTS.value]
                
                if existing_edge:
                    # æ›´æ–°ç°æœ‰è¾¹
                    existing_edge.weight = edge_data.get('weight', 1.0)
                    existing_edge.edge_type = edge_type
                    existing_edge.is_vertical = is_vertical
                    updated_edges += 1
                else:
                    # åˆ›å»ºæ–°è¾¹
                    edge = Edge(
                        from_node_id=from_id,
                        to_node_id=to_id,
                        weight=edge_data.get('weight', 1.0),
                        edge_type=edge_type,
                        is_vertical=is_vertical,
                    )
                    session.add(edge)
                    imported_edges += 1
            
            await session.commit()
            if verbose:
                print(f"âœ… è¾¹å¯¼å…¥å®Œæˆ: æ–°å¢ {imported_edges}, æ›´æ–° {updated_edges}, è·³è¿‡ {skipped_edges}")
            
            return True
            
        except Exception as e:
            await session.rollback()
            print(f"âŒ å¯¼å…¥å¤±è´¥ ({json_file}): {e}")
            return False


def find_json_files(paths: List[str]) -> List[str]:
    """
    æŸ¥æ‰¾æ‰€æœ‰ JSON æ–‡ä»¶
    
    Args:
        paths: æ–‡ä»¶è·¯å¾„æˆ–ç›®å½•è·¯å¾„åˆ—è¡¨ï¼Œæ”¯æŒé€šé…ç¬¦
        
    Returns:
        JSON æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    json_files = []
    
    for path_str in paths:
        path = Path(path_str)
        
        # å¦‚æœæ˜¯æ–‡ä»¶ï¼Œç›´æ¥æ·»åŠ 
        if path.is_file():
            if path.suffix.lower() == '.json':
                json_files.append(str(path.resolve()))
            else:
                print(f"âš ï¸  è·³è¿‡é JSON æ–‡ä»¶: {path_str}")
        
        # å¦‚æœæ˜¯ç›®å½•ï¼ŒæŸ¥æ‰¾æ‰€æœ‰ JSON æ–‡ä»¶
        elif path.is_dir():
            json_files.extend([
                str(p.resolve()) 
                for p in path.rglob('*.json')
            ])
        
        # å¦‚æœæ˜¯é€šé…ç¬¦æ¨¡å¼
        elif '*' in path_str or '?' in path_str:
            matched = glob.glob(path_str, recursive=True)
            json_files.extend([
                str(Path(f).resolve())
                for f in matched
                if Path(f).suffix.lower() == '.json'
            ])
        
        else:
            print(f"âš ï¸  è·¯å¾„ä¸å­˜åœ¨: {path_str}")
    
    # å»é‡å¹¶æ’åº
    json_files = sorted(list(set(json_files)))
    return json_files


async def batch_import(
    paths: List[str],
    clear_existing: bool = False,
    verbose: bool = True
):
    """
    æ‰¹é‡å¯¼å…¥å¤šä¸ª JSON æ–‡ä»¶
    
    Args:
        paths: æ–‡ä»¶è·¯å¾„ã€ç›®å½•è·¯å¾„æˆ–é€šé…ç¬¦æ¨¡å¼åˆ—è¡¨
        clear_existing: æ˜¯å¦åœ¨å¯¼å…¥å‰æ¸…é™¤ç°æœ‰æ•°æ®
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    """
    # æŸ¥æ‰¾æ‰€æœ‰ JSON æ–‡ä»¶
    json_files = find_json_files(paths)
    
    if not json_files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½• JSON æ–‡ä»¶")
        return
    
    print(f"\nğŸ” æ‰¾åˆ° {len(json_files)} ä¸ª JSON æ–‡ä»¶:")
    for i, f in enumerate(json_files, 1):
        print(f"  {i}. {f}")
    
    # ç¡®è®¤
    if verbose:
        response = input(f"\næ˜¯å¦å¯¼å…¥è¿™ {len(json_files)} ä¸ªæ–‡ä»¶? (y/n): ").strip().lower()
        if response != 'y' and response != 'yes':
            print("âŒ å·²å–æ¶ˆå¯¼å…¥")
            return
    
    # åˆå§‹åŒ–æ•°æ®åº“
    await init_db()
    
    # æ‰¹é‡å¯¼å…¥
    print(f"\nğŸš€ å¼€å§‹æ‰¹é‡å¯¼å…¥...")
    success_count = 0
    fail_count = 0
    
    for i, json_file in enumerate(json_files, 1):
        print(f"\n{'='*60}")
        print(f"ğŸ“¦ å¤„ç†æ–‡ä»¶ {i}/{len(json_files)}: {Path(json_file).name}")
        print(f"{'='*60}")
        
        # åªåœ¨ç¬¬ä¸€ä¸ªæ–‡ä»¶æ—¶æ¸…é™¤ç°æœ‰æ•°æ®
        should_clear = clear_existing and i == 1
        
        success = await import_map_data(json_file, clear_existing=should_clear, verbose=verbose)
        
        if success:
            success_count += 1
            print(f"âœ… æ–‡ä»¶ {i} å¯¼å…¥æˆåŠŸ")
        else:
            fail_count += 1
            print(f"âŒ æ–‡ä»¶ {i} å¯¼å…¥å¤±è´¥")
    
    # ç»Ÿè®¡ä¿¡æ¯
    print(f"\n{'='*60}")
    print(f"ğŸ‰ æ‰¹é‡å¯¼å…¥å®Œæˆ!")
    print(f"âœ… æˆåŠŸ: {success_count} ä¸ªæ–‡ä»¶")
    print(f"âŒ å¤±è´¥: {fail_count} ä¸ªæ–‡ä»¶")
    print(f"{'='*60}")


async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='æ‰¹é‡å¯¼å…¥åœ°å›¾æ•°æ®åˆ°æ•°æ®åº“',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # å¯¼å…¥å•ä¸ªæ–‡ä»¶
  python import_map_data_batch.py project1230/campus_map.json
  
  # å¯¼å…¥å¤šä¸ªæ–‡ä»¶
  python import_map_data_batch.py project1230/campus_map.json project1230/campus_map_add.json
  
  # å¯¼å…¥ç›®å½•ä¸‹æ‰€æœ‰ JSON æ–‡ä»¶
  python import_map_data_batch.py project1230/
  
  # ä½¿ç”¨é€šé…ç¬¦
  python import_map_data_batch.py project1230/*.json
  
  # æ¸…é™¤ç°æœ‰æ•°æ®åå¯¼å…¥
  python import_map_data_batch.py project1230/ --clear
        """
    )
    parser.add_argument(
        'paths',
        nargs='+',
        help='JSON æ–‡ä»¶è·¯å¾„ã€ç›®å½•è·¯å¾„æˆ–é€šé…ç¬¦æ¨¡å¼ï¼ˆå¯æŒ‡å®šå¤šä¸ªï¼‰'
    )
    parser.add_argument(
        '--clear',
        action='store_true',
        help='æ¸…é™¤ç°æœ‰æ•°æ®åå†å¯¼å…¥ï¼ˆåªåœ¨ç¬¬ä¸€ä¸ªæ–‡ä»¶æ—¶æ¸…é™¤ï¼‰'
    )
    parser.add_argument(
        '--quiet',
        action='store_true',
        help='é™é»˜æ¨¡å¼ï¼Œä¸æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯'
    )
    
    args = parser.parse_args()
    
    await batch_import(args.paths, clear_existing=args.clear, verbose=not args.quiet)


if __name__ == "__main__":
    asyncio.run(main())


